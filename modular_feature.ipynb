{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_metadata = {\n",
    "    \"monash_tourism_monthly\": {\"prediction_length\": 24},\n",
    "    \"m4_hourly\": {\"prediction_length\": 48},\n",
    "}\n",
    "\n",
    "dataset_choice = \"monash_tourism_monthly\"\n",
    "num_time_series_subset = 2\n",
    "prediction_length = dataset_metadata[dataset_choice][\"prediction_length\"]\n",
    "\n",
    "# LOADING DATA\n",
    "def load_data(dataset_choice, num_time_series_subset):\n",
    "\n",
    "    from datasets import load_dataset\n",
    "    from autogluon.timeseries import TimeSeriesDataFrame\n",
    "\n",
    "    from tabpfn_time_series.data_preparation import to_gluonts_univariate, generate_test_X\n",
    "\n",
    "    prediction_length = dataset_metadata[dataset_choice][\"prediction_length\"]\n",
    "    dataset = load_dataset(\"autogluon/chronos_datasets\", dataset_choice)\n",
    "\n",
    "    tsdf = TimeSeriesDataFrame(to_gluonts_univariate(dataset[\"train\"]))\n",
    "    tsdf = tsdf[\n",
    "        tsdf.index.get_level_values(\"item_id\").isin(tsdf.item_ids[:num_time_series_subset])\n",
    "    ]\n",
    "    train_tsdf, test_tsdf_ground_truth = tsdf.train_test_split(\n",
    "        prediction_length=prediction_length\n",
    "    )\n",
    "    test_tsdf = generate_test_X(train_tsdf, prediction_length)\n",
    "\n",
    "    return tsdf, train_tsdf, test_tsdf_ground_truth, test_tsdf\n",
    "\n",
    "\n",
    "# Call data\n",
    "tsdf, train_tsdf, test_tsdf_ground_truth, test_tsdf = load_data(dataset_choice, num_time_series_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Feature Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Feature Transformer\n",
    "from tabpfn_time_series import FeatureTransformer\n",
    "from tabpfn_time_series.features import (\n",
    "    RunningIndexFeature,\n",
    "    CalendarFeature,\n",
    "    AutoSeasonalFeature,\n",
    ")\n",
    "\n",
    "selected_features = [\n",
    "    RunningIndexFeature(),\n",
    "    CalendarFeature(),\n",
    "    AutoSeasonalFeature(),\n",
    "]\n",
    "\n",
    "feature_transformer = FeatureTransformer(selected_features)\n",
    "\n",
    "# Original Feature Transformer Time Series DataFrame\n",
    "train_tsdf_original, test_tsdf_original = feature_transformer.transform(train_tsdf, test_tsdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of feature transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn_time_series.features.utils_pipeline import from_autogluon_tsdf_to_df, from_df_to_autogluon_tsdf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 seasonal periods: [(12.0, 72368.19862358051), (6.0, 31799.917445186442), (4.0, 18986.89682967007), (2.0, 7689.506995250422), (3.0, 7597.16411492776)]\n",
      "All common columns match between train_df and train_tsdf_original for all item_ids.\n",
      "Found 4 seasonal periods: [(12.0, 1806838.9715574959), (163.0, 677915.7804036293), (6.0, 571950.6753520791), (3.0, 236132.8087148125)]\n",
      "All common columns match between train_df and train_tsdf_original for all item_ids.\n"
     ]
    }
   ],
   "source": [
    "from tabpfn_time_series.features.feature_pipeline import (\n",
    "    RunningIndexFeature,\n",
    "    AutoSeasonalFeatureSklearn,\n",
    "    CalendarFeatureSklearn,\n",
    ")\n",
    "from tabpfn_time_series.features.utils_pipeline import train_test_split_time_series\n",
    "from tabpfn_time_series.features.tests.test_pipelines import test_train_test_split_time_series,test_feature_transformer\n",
    "\n",
    "# Split your data into train_df and test_df (with columns: item_id, timestamp, target)\n",
    "pipeline = [\n",
    "    RunningIndexFeature(mode=\"per_item\"),\n",
    "    # RunningIndexFeature(mode=\"global_timestamp\"),\n",
    "    AutoSeasonalFeatureSklearn(),\n",
    "    CalendarFeatureSklearn(),\n",
    "]\n",
    "\n",
    "tsdf, train_tsdf, test_tsdf_ground_truth, test_tsdf = load_data(dataset_choice, num_time_series_subset)\n",
    "\n",
    "# convert to pandas dataframe\n",
    "df = from_autogluon_tsdf_to_df(tsdf)   \n",
    "train_df, test_df, ground_truth = train_test_split_time_series(df, prediction_length)\n",
    "\n",
    "# from tabpfn_time_series.features.predict_pipeline import TabPFNTimeSeriesPredictor\n",
    "\n",
    "PREDICTIONS = []\n",
    "\n",
    "# get all unique item_id and loop through them and print them out\n",
    "unique_item_id = train_df['item_id'].unique()\n",
    "for item_id in unique_item_id:\n",
    "    train_item_id = train_df[train_df['item_id'] == item_id]\n",
    "    test_item_id = test_df[test_df['item_id'] == item_id]\n",
    "    \n",
    "    # Fit on train only\n",
    "    for feat in pipeline:\n",
    "        feat.fit(train_item_id)\n",
    "    \n",
    "    # Transform both train and test\n",
    "    train_feat = train_item_id.copy()\n",
    "    test_feat = test_item_id.copy()\n",
    "    for feat in pipeline:\n",
    "        # print(feat)\n",
    "        # print(train_feat['timestamp'].head())\n",
    "        train_feat = feat.transform(train_feat)\n",
    "        test_feat = feat.transform(test_feat)\n",
    "    \n",
    "    # tests\n",
    "    test_feature_transformer(train_feat, train_tsdf_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn_ts",
   "language": "python",
   "name": "ts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
